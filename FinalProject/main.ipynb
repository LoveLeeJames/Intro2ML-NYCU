{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from thop import profile\n",
    "\n",
    "# Define transformations for training and testing datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set dataset paths\n",
    "train_dataset = datasets.ImageFolder(root='dataset/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='dataset/test', transform=transform)\n",
    "\n",
    "# Adjust batch size\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Enhanced structure\n",
    "class HardSwish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * F.relu6(x + 3) / 6\n",
    "\n",
    "class MixConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes, stride=1, padding=1):\n",
    "        super(MixConv, self).__init__()\n",
    "        self.groups = len(kernel_sizes)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels // self.groups, kernel_size=k, stride=stride, padding=padding, groups=in_channels)\n",
    "            for k in kernel_sizes\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        splits = torch.split(x, x.size(1) // self.groups, 1)\n",
    "        outputs = [conv(split) for conv, split in zip(self.convs, splits)]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class SandGlassBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor, stride):\n",
    "        super(SandGlassBlock, self).__init__()\n",
    "        self.stride = stride\n",
    "        mid_channels = in_channels * expansion_factor\n",
    "\n",
    "        self.expand = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            HardSwish()\n",
    "        )\n",
    "\n",
    "        self.dwconv = nn.Sequential(\n",
    "            MixConv(mid_channels, mid_channels, kernel_sizes=[3, 5, 7], stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            HardSwish()\n",
    "        )\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stride == 1 and x.size(1) == self.project[1].num_features:\n",
    "            return x + self.project(self.dwconv(self.expand(x)))\n",
    "        else:\n",
    "            return self.project(self.dwconv(self.expand(x)))\n",
    "\n",
    "# Define the model (EfficientNet-B0 with custom layers)\n",
    "class CustomEfficientNet(nn.Module):\n",
    "    def replace_mbconv(self):\n",
    "        def replace_block(block, expansion_factor):\n",
    "            in_channels = block[0][0].in_channels\n",
    "            out_channels = block[-1].out_channels\n",
    "            stride = block[0][0].stride\n",
    "            return SandGlassBlock(in_channels, out_channels, expansion_factor=expansion_factor, stride=stride)\n",
    "\n",
    "        for name, module in self.base_model.features.named_children():\n",
    "            if isinstance(module, models.efficientnet.MBConv):\n",
    "                if module.block[1].expand_ratio == 1:  # MBConv1\n",
    "                    new_module = replace_block(module.block, expansion_factor=1)\n",
    "                elif module.block[1].expand_ratio == 6:  # MBConv6\n",
    "                    new_module = replace_block(module.block, expansion_factor=6)\n",
    "\n",
    "                setattr(self.base_model.features, name, new_module)\n",
    "                \n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomEfficientNet, self).__init__()\n",
    "        self.base_model = models.efficientnet_b0(pretrained=True)\n",
    "        \n",
    "        # Replace MBConv1 and MBConv6 blocks\n",
    "        self.replace_mbconv()\n",
    "\n",
    "        # Modify the classifier\n",
    "        num_ftrs = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            HardSwish(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "model = CustomEfficientNet(num_classes=2)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        \n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        print('-' * 15)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, train_loader, criterion, optimizer, num_epochs=25)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs('Saved Model', exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'Saved Model/EnhancedENetB0_v0.pth')\n",
    "\n",
    "# Load the model for inference or further evaluation\n",
    "model.load_state_dict(torch.load('Saved Model/EnhancedENetB0_v0.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Calculate training and testing accuracy\n",
    "train_accuracy = calculate_accuracy(train_loader, model)\n",
    "test_accuracy = calculate_accuracy(test_loader, model)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}%')\n",
    "print(f'Testing Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# Calculate FLOPs and number of parameters\n",
    "input_size = (1, 3, 224, 224)\n",
    "flops, params = profile(model, inputs=(torch.randn(input_size).to(device),))\n",
    "\n",
    "print(f'FLOPs: {flops}')\n",
    "print(f'Number of parameters: {params}')\n",
    "\n",
    "# Print model summary\n",
    "summary(model, input_size[1:])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
